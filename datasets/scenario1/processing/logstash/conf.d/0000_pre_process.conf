filter {
    # remove incorrect host fields
    if [host] {
        mutate { remove_field => ["host"] }
    }

    # fix path field to ecs
    if [path] {
        mutate {
            rename => [
                "path","[log][file][path]"
            ]
        }
    }

    # add path relative to gather dir to metadata
    grok {
        # only match the sub path in the hosts gather logs dir
        match => {
            "[log][file][path]" => "/home/frankm/test_dataset/gather/%{GREEDYDATA}/logs/%{GREEDYDATA:[@metadata][file][relative_path]}"
        }
    }

    mutate {
        # add correct host field from gathered dataset
        rename => [
                "[@metadata][kyoushi][host]","[host]"
        ]
    }

    # add log lines based on current event count for the file
    # !!! WARNING: This only works in ordered mode, i.e., a single worker
    #              Also line number counters do not persist across logstash runs
    if ![log][file][line] {
        ruby {
            init => "@line_numbers = Hash.new(0)"
            code => '
                tags = event.get("tags")
                path = event.get("[log][file][path]")
                @line_numbers[path] += 1
                event.set("[log][file][line]", @line_numbers[path])
                # for multilines we also save the count of extra lines
                # and increase the line number counter accordingly
                if not tags.nil? and tags.include? "multiline"
                    line_count = event.get("message").lines.count - 1
                    event.set("[log][file][multilines]", line_count)
                    @line_numbers[path] += line_count
                end
            '
        }
    }

    ruby {
        # create a few globals
        init => '
            @@fallback_timestamp = Hash.new(LogStash::Timestamp.at(1616454000.0))
            @@observe_start = LogStash::Timestamp.at(1616454000.0)
            @@observe_end = LogStash::Timestamp.at(1616886000.0)
        '
        code => ''
    }
}